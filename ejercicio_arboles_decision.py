# -*- coding: utf-8 -*-
"""Ejercicio_Arboles_Decision.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RUwNgRO0VbDvbLaGogokXviWhTMyhzGQ

Estudiantes: David Ricardo Jimenez Nuñez
Cesar Martinez Andrade
"""

# 1. Importar las librerías necesarias
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 2. Cargar el dataset Iris
dataset = load_iris()
X = dataset.data  # Características (features)
y = dataset.target  # Etiquetas (clases)

# Convertir a DataFrame para mejor visualización
df = pd.DataFrame(X, columns=dataset.feature_names)
df['target'] = y

# 3. (Opcional) Filtrar solo dos clases para un problema binario
binary_class = False  # Cambiar a True si se desea solo dos clases
if binary_class:
    df = df[df['target'] != 2]  # Eliminamos la clase 2
    X = df.iloc[:, :-1].values
    y = df['target'].values

# 4. Dividir en conjunto de entrenamiento (70%) y prueba (30%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 5. Entrenar un Árbol de Decisión
criterion = 'gini'  # Cambiar a 'entropy' si se desea usar Ganancia de Información
max_depth = 3  # Cambiar la profundidad máxima del árbol para experimentar

dt = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, random_state=42)
dt.fit(X_train, y_train)

# 6. Evaluar el modelo
y_pred = dt.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Precisión del modelo: {accuracy:.4f}")

# 7. Generar reporte de clasificación
print("\nReporte de clasificación:")
print(classification_report(y_test, y_pred, target_names=dataset.target_names))

# 8. Matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=dataset.target_names, yticklabels=dataset.target_names)
plt.xlabel("Predicción")
plt.ylabel("Real")
plt.title("Matriz de Confusión")
plt.show()

# 9. Visualizar el árbol de decisión
plt.figure(figsize=(12, 8))
plot_tree(dt, feature_names=dataset.feature_names, class_names=dataset.target_names, filled=True)
plt.show()

# 10. Analizar la importancia de las características
importances = dt.feature_importances_
feature_importance_df = pd.DataFrame({'Feature': dataset.feature_names, 'Importance': importances})
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)
print("\nImportancia de las características:")
print(feature_importance_df)

# Gráfica de importancia de características
plt.figure(figsize=(8,5))
sns.barplot(
    x=feature_importance_df['Importance'],
    y=feature_importance_df['Feature'],
    hue=feature_importance_df['Feature'],  # Se especifica hue para evitar warnings
    palette='viridis',
    legend=False  # Se desactiva la leyenda ya que no es necesaria
)
plt.xlabel("Importancia")
plt.ylabel("Características")
plt.title("Importancia de las Características")
plt.show()